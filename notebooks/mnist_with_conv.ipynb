{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from edunets import functional, losses\n",
    "from edunets.tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = np.arange(9).reshape(3,3)\n",
    "print(arr)\n",
    "arr[[0, 0], [2, 2]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cross-correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the cross correlation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [1., 2., 3., 0.],\n",
    "    [4., 5., 6., 0.],\n",
    "    [7., 8., 9., 0.],\n",
    "    [-1., -1., -1., -1.]\n",
    "])\n",
    "\n",
    "a_small = np.array([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.],\n",
    "    [7., 8., 9.],\n",
    "])\n",
    "\n",
    "v = np.array([\n",
    "    [2., 3.],\n",
    "    [3., 2.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[30.]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch only supports 3 dimentional vectors for F.conv so we add dummy dimensions\n",
    "x = torch.tensor(a_small, dtype=float)[None, None]\n",
    "w = torch.tensor(v, dtype=float)[None, None]\n",
    "F.conv2d(x, w, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30., 40., 24.],\n",
       "       [60., 70., 39.],\n",
       "       [33., 38., 13.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor(a).correlate(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if the gradients match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[30., 40., 24.],\n",
      "          [60., 70., 39.],\n",
      "          [33., 38., 13.]]]], dtype=torch.float64,\n",
      "       grad_fn=<ThnnConv2DBackward>)\n",
      "tensor([[[[ 2.,  5.,  5.,  3.],\n",
      "          [ 5., 10., 10.,  5.],\n",
      "          [ 5., 10., 10.,  5.],\n",
      "          [ 3.,  5.,  5.,  2.]]]], dtype=torch.float64)\n",
      "tensor([[[[45., 33.],\n",
      "          [36., 25.]]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(a[None, None], dtype=float, requires_grad=True)\n",
    "w = torch.tensor(v[None, None], dtype=float, requires_grad=True)\n",
    "out = F.conv2d(x, w)\n",
    "print(out)\n",
    "out.backward(torch.ones(out.shape))\n",
    "\n",
    "print(x.grad)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[30., 40., 24.],\n",
      "         [60., 70., 39.],\n",
      "         [33., 38., 13.]]]], dtype=float32)\n",
      "[[[[ 2.  5.  5.  3.]\n",
      "   [ 5. 10. 10.  5.]\n",
      "   [ 5. 10. 10.  5.]\n",
      "   [ 3.  5.  5.  2.]]]]\n",
      "[[[[45. 33.]\n",
      "   [36. 25.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = Tensor(a[None, None], requires_grad=True)\n",
    "w = Tensor(v[None, None], requires_grad=True)\n",
    "out = x.correlate(w)\n",
    "print(out)\n",
    "out.backward(Tensor.ones(*out.shape))\n",
    "\n",
    "print(x.grad)\n",
    "print(w.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They do yay! Now we have to try and add the other paramaters that are in torch's cond1d, like padding and stride."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-correlation with a stride"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with stride, meaning how much the kernel shifts when performing cross-correlation. Default is 1, so the kernel just slides naturaly accross the input. \n",
    "\n",
    "With stride = 1, we get, for input=[1,2,3,4,5,6] and kernel=[6,7]:\n",
    "\n",
    "6*1 + 7*2 = 20\n",
    "\n",
    "6*2 + 7*3 = 33\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "6*4 + 7*5 = 59\n",
    "\n",
    "so the convolution is [20, 33, 46, 59]\n",
    "\n",
    "With stride = 2 we just take the index that are equal to 0 modulo 2\n",
    "this of course generelizes to any value of stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[30., 24.],\n",
      "          [33., 13.]]]], dtype=torch.float64, grad_fn=<ThnnConv2DBackward>)\n",
      "tensor([[[[2., 3., 2., 3.],\n",
      "          [3., 2., 3., 2.],\n",
      "          [2., 3., 2., 3.],\n",
      "          [3., 2., 3., 2.]]]], dtype=torch.float64)\n",
      "tensor([[[[20., 10.],\n",
      "          [ 8.,  3.]]]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[30., 24.],\n",
       "          [33., 13.]]]], dtype=torch.float64, grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 2\n",
    "\n",
    "x = torch.tensor(a[None, None], dtype=float, requires_grad=True)\n",
    "w = torch.tensor(v[None, None], dtype=float, requires_grad=True)\n",
    "out = F.conv1d(x, w, stride=stride)\n",
    "print(out)\n",
    "out.backward(torch.ones(out.shape))\n",
    "\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[30., 40., 24.],\n",
      "         [60., 70., 39.],\n",
      "         [33., 38., 13.]]]], dtype=float32)\n",
      "tensor([30., 24., 33., 13.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from edunets.utils import indexes_by_stride\n",
    "\n",
    "x = Tensor(a[None, None], dtype=float, requires_grad=True)\n",
    "w = Tensor(v[None, None], dtype=float, requires_grad=True)\n",
    "out = x.correlate(w)\n",
    "\n",
    "print(out)\n",
    "\n",
    "idxes = indexes_by_stride(out, stride)\n",
    "\n",
    "# Selecting values based on stride\n",
    "out = out[idxes]\n",
    "\n",
    "print(out)\n",
    "\n",
    "# Reshape back "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "\n",
    "The first step is to implement a convolution layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input.shape\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        \n",
    "        self.kernels = Tensor.uniform(*self.kernels_shape)\n",
    "        self.biases = Tensor.uniform(*self.output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.biases.copy()\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                output[i] = output[i] + x[j].correlate(self.kernels[i,j], mode=\"valid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dbd43346cf4060a7c5249e62daf2cb2395365dab3b14076ef7b34680f245741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
